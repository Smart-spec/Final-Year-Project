{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06ff666d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 81723 ships across 42556 images.\n",
      "Starting to create masks...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Creates integer-based masks from RLE data.\"\"\"\n",
    "from os import path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "DATA_DIR = r'C:\\Users\\ZEPHYRUS\\Downloads\\kaggle data'\n",
    "MASK_DIR = path.join(DATA_DIR, r'C:\\Users\\ZEPHYRUS\\Downloads\\kaggle data')\n",
    "\n",
    "def get_mask(encoded_pixels, dims):\n",
    "    \"\"\"Get integer-based mask from multiple run length encoded ships.\"\"\"\n",
    "\n",
    "    # Init mask with all 0-class pixels.\n",
    "    mask = np.zeros(dims[0] * dims[1], dtype = np.uint8)\n",
    "\n",
    "    for obj_id, curr_encoded in enumerate(encoded_pixels):\n",
    "\n",
    "        s = curr_encoded.split()\n",
    "\n",
    "        for i in range(len(s) // 2):\n",
    "            start = int(s[2 * i]) - 1\n",
    "            length = int(s[2 * i + 1])\n",
    "            mask[start : start + length] = obj_id + 1\n",
    "\n",
    "    return mask.reshape(dims).T\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Load training metadata.\n",
    "    metadata = path.join(DATA_DIR, 'train_ship_segmentations_v2.csv')\n",
    "    df_metadata = pd.read_csv(metadata)\n",
    "\n",
    "    # Corrupted images.\n",
    "    exclude_list = ['6384c3e78.jpg', '13703f040.jpg', '14715c06d.jpg',\n",
    "        '33e0ff2d5.jpg', '4d4e09f2a.jpg', '877691df8.jpg', '8b909bb20.jpg',\n",
    "        'a8d99130e.jpg', 'ad55c3143.jpg', 'c8260c541.jpg', 'd6c7f17c7.jpg',\n",
    "        'dc3e7c901.jpg', 'e44dffe88.jpg', 'ef87bad36.jpg', 'f083256d8.jpg']\n",
    "\n",
    "    for corrupted in exclude_list:\n",
    "        df_metadata = df_metadata[~df_metadata.ImageId.str.contains(corrupted)]\n",
    "\n",
    "    # Remove images without ships.\n",
    "    df_metadata.dropna(inplace = True)\n",
    "\n",
    "    n_ships = len(df_metadata)\n",
    "    image_ids = np.unique(df_metadata.ImageId.tolist())\n",
    "    print(f'There are {n_ships} ships across {len(image_ids)} images.')\n",
    "\n",
    "    print('Starting to create masks...')\n",
    "\n",
    "    for image_id in image_ids:\n",
    "\n",
    "        fn_mask = path.join(MASK_DIR, image_id.replace('.jpg', '_mask.png'))\n",
    "\n",
    "        samples = df_metadata[df_metadata['ImageId'] == image_id]\n",
    "        encoded_pixels = samples.EncodedPixels.tolist()\n",
    "        mask = get_mask(encoded_pixels, (768, 768))\n",
    "\n",
    "        im = Image.fromarray(mask)\n",
    "        im.save(fn_mask)\n",
    "\n",
    "    print('Done.')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6244d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Custom dataset for Airbus images.\"\"\"\n",
    "from torch.utils.data import Dataset\n",
    "from os import path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class AirbusShipDetection(Dataset):\n",
    "\n",
    "    def __init__(self, image_ids, dir_images, dir_masks, transforms = None):\n",
    "\n",
    "        self.image_ids = image_ids\n",
    "        self.dir_images = dir_images\n",
    "        self.dir_masks = dir_masks\n",
    "        self._transforms = transforms\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        # Read the RGB image.\n",
    "        fn_image = f'{self.image_ids[idx]}.jpg'\n",
    "        path_image = path.join(self.dir_images, fn_image)\n",
    "        image = Image.open(path_image).convert(\"RGB\")\n",
    "\n",
    "        # Read the integer-based mask.\n",
    "        fn_mask = f'{self.image_ids[idx]}_mask.png'\n",
    "        path_mask = path.join(self.dir_masks, fn_mask)\n",
    "        mask = np.array(Image.open(path_mask))\n",
    "\n",
    "        # Instances are encoded with different integers.\n",
    "        obj_ids = np.unique(mask)\n",
    "\n",
    "        # We remove the background (id=0) from the mask.\n",
    "        obj_ids = obj_ids[1:]\n",
    "        num_objs = len(obj_ids)\n",
    "\n",
    "        # Split the mask into a set of binary masks\n",
    "        # masks.shape[0] = number of istances\n",
    "        masks = mask == obj_ids[:, None, None]\n",
    "\n",
    "        # Get bounding box of each mask.\n",
    "        boxes = []\n",
    "        for mask in masks:\n",
    "\n",
    "            pos = np.where(mask)\n",
    "\n",
    "            xmin = np.min(pos[1])\n",
    "            xmax = np.max(pos[1])\n",
    "            ymin = np.min(pos[0])\n",
    "            ymax = np.max(pos[0])\n",
    "\n",
    "            # Enforce a positive area.\n",
    "            if xmax - xmin < 1:\n",
    "                xmax += 1\n",
    "            if ymax - ymin < 1:\n",
    "                ymax += 1\n",
    "\n",
    "            boxes.append([xmin, ymin, xmax, ymax])\n",
    "\n",
    "        boxes = torch.as_tensor(boxes, dtype = torch.float32)\n",
    "\n",
    "        # Compute the area.\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "\n",
    "        # Only one class (ships).\n",
    "        labels = torch.ones((num_objs,), dtype = torch.int64)\n",
    "        masks = torch.as_tensor(masks, dtype = torch.uint8)\n",
    "\n",
    "        # Crowd flag not applicable here.\n",
    "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "\n",
    "        image_id = torch.tensor([idx])\n",
    "\n",
    "        target = {}\n",
    "        target['boxes'] = boxes\n",
    "        target['labels'] = labels\n",
    "        target['masks'] = masks\n",
    "        target['image_id'] = image_id\n",
    "        target['area'] = area\n",
    "        target['iscrowd'] = iscrowd\n",
    "\n",
    "        # Apply image augmentation.\n",
    "        if self._transforms:\n",
    "            image, target = self._transforms(image, target)\n",
    "\n",
    "        return image, target\n",
    "\n",
    "    def __len__(self):\n",
    "        # return length of\n",
    "        return len(self.image_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e27487b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (635657696.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[12], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    masks = pd.read_csv(\"C:\\Users\\ZEPHYRUS\\Downloads\\kaggle data\\trainship\")\u001b[0m\n\u001b[1;37m                                                                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "masks = pd.read_csv(\"C:\\Users\\ZEPHYRUS\\Downloads\\kaggle data\\trainship\")\n",
    "masks.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09db2a39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
